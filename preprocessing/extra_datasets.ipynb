{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import json\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import random\r\n",
    "import pathlib"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "f = open('bind_frequency.json')\r\n",
    "data1 = json.load(f)\r\n",
    "data2 = dict()\r\n",
    "keys = data1.keys()\r\n",
    "for k in keys:\r\n",
    "    v = data1[k]\r\n",
    "    if v in data2:\r\n",
    "        data2[v] += 1\r\n",
    "    else:\r\n",
    "        data2[v] = 1\r\n",
    "        \r\n",
    "bp = data2.keys()\r\n",
    "freq = data2.values()\r\n",
    "#print(bp)\r\n",
    "#print(freq)\r\n",
    "df = pd.DataFrame()\r\n",
    "df.reset_index(level=0, inplace=True)\r\n",
    "df['partner_count'] = bp\r\n",
    "df['frequency'] = freq\r\n",
    "df_red = df[df.partner_count > 10]\r\n",
    "#print(df_red)\r\n",
    "total = df_red.partner_count.sum()\r\n",
    "print(\"Total dropped:\", total)\r\n",
    "print(df_red.sort_values(by='partner_count'))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total dropped: 16601\n",
      "    index  partner_count  frequency\n",
      "15    NaN             11        223\n",
      "16    NaN             12        193\n",
      "31    NaN             13        163\n",
      "23    NaN             14        147\n",
      "26    NaN             15        124\n",
      "..    ...            ...        ...\n",
      "85    NaN            311          1\n",
      "74    NaN            379          1\n",
      "116   NaN            411          1\n",
      "75    NaN            471          1\n",
      "88    NaN            630          1\n",
      "\n",
      "[151 rows x 3 columns]\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "f = open('bind_frequency.json')\r\n",
    "temp = json.load(f)\r\n",
    "\r\n",
    "new_df = pd.DataFrame.from_dict(temp, orient='index')\r\n",
    "prot_fr = new_df.stack().reset_index(level=1, drop=True).to_frame(name='freq')\r\n",
    "factor = []\r\n",
    "prot_fr_r = prot_fr[prot_fr.freq > 10]\r\n",
    "for i, row in prot_fr_r.iterrows():\r\n",
    "    factor.append(np.round((row['freq']/4.25)))\r\n",
    "prot_fr_r['factor'] = factor\r\n",
    "prot_fr_r"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\kmmbd\\anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq</th>\n",
       "      <th>factor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A1L4K1</th>\n",
       "      <td>47</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A5D8V6</th>\n",
       "      <td>32</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A5YKK6</th>\n",
       "      <td>24</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A8K1F4</th>\n",
       "      <td>83</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A8K8P3</th>\n",
       "      <td>20</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>O95147</th>\n",
       "      <td>16</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q9Y570</th>\n",
       "      <td>14</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P0DOE7</th>\n",
       "      <td>25</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q9BVW5</th>\n",
       "      <td>11</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q96QE5</th>\n",
       "      <td>11</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2345 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        freq  factor\n",
       "A1L4K1    47    11.0\n",
       "A5D8V6    32     8.0\n",
       "A5YKK6    24     6.0\n",
       "A8K1F4    83    20.0\n",
       "A8K8P3    20     5.0\n",
       "...      ...     ...\n",
       "O95147    16     4.0\n",
       "Q9Y570    14     3.0\n",
       "P0DOE7    25     6.0\n",
       "Q9BVW5    11     3.0\n",
       "Q96QE5    11     3.0\n",
       "\n",
       "[2345 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "# save the df\r\n",
    "prot_fr_r.to_csv('prot_fr_list_factor.csv', index=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_file = 'train_positive.csv'\r\n",
    "df_train = pd.read_csv(train_file, sep=\",\", dtype='unicode')\r\n",
    "list_A = df_train['int_A']\r\n",
    "list_B = df_train['int_B']\r\n",
    "list_full = [*list_A, *list_B]\r\n",
    "neg_prot = list(prot_fr_r.index.values)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "source": [
    "neg_freq_bal = pd.DataFrame(columns=['int_A', 'int_B'])\r\n",
    "j = 0\r\n",
    "list_A = []\r\n",
    "list_B = []\r\n",
    "for p in neg_prot:\r\n",
    "    f = prot_fr_r.loc[neg_prot[j], 'factor']\r\n",
    "    j+=1\r\n",
    "    for i in range(int(f)):\r\n",
    "        list_A.append(p)\r\n",
    "        list_B.append(random.choice(list_full))\r\n",
    "#print(list_A)\r\n",
    "neg_freq_bal['int_A'] = list_A\r\n",
    "neg_freq_bal['int_B'] = list_B\r\n",
    "print(neg_freq_bal)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "        int_A   int_B\n",
      "0      A1L4K1  Q81QL7\n",
      "1      A1L4K1  Q13563\n",
      "2      A1L4K1  D3JIB2\n",
      "3      A1L4K1  Q9P2Q2\n",
      "4      A1L4K1  P38770\n",
      "...       ...     ...\n",
      "16808  Q9BVW5  Q9UEW3\n",
      "16809  Q9BVW5  Q12983\n",
      "16810  Q96QE5  P02775\n",
      "16811  Q96QE5  Q9P291\n",
      "16812  Q96QE5  Q56950\n",
      "\n",
      "[16813 rows x 2 columns]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "source": [
    "neg_freq_bal_r = neg_freq_bal.drop_duplicates()\r\n",
    "neg_freq_bal_r"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>int_A</th>\n",
       "      <th>int_B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A1L4K1</td>\n",
       "      <td>Q81QL7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A1L4K1</td>\n",
       "      <td>Q13563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1L4K1</td>\n",
       "      <td>D3JIB2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1L4K1</td>\n",
       "      <td>Q9P2Q2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A1L4K1</td>\n",
       "      <td>P38770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16808</th>\n",
       "      <td>Q9BVW5</td>\n",
       "      <td>Q9UEW3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16809</th>\n",
       "      <td>Q9BVW5</td>\n",
       "      <td>Q12983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16810</th>\n",
       "      <td>Q96QE5</td>\n",
       "      <td>P02775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16811</th>\n",
       "      <td>Q96QE5</td>\n",
       "      <td>Q9P291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16812</th>\n",
       "      <td>Q96QE5</td>\n",
       "      <td>Q56950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16766 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        int_A   int_B\n",
       "0      A1L4K1  Q81QL7\n",
       "1      A1L4K1  Q13563\n",
       "2      A1L4K1  D3JIB2\n",
       "3      A1L4K1  Q9P2Q2\n",
       "4      A1L4K1  P38770\n",
       "...       ...     ...\n",
       "16808  Q9BVW5  Q9UEW3\n",
       "16809  Q9BVW5  Q12983\n",
       "16810  Q96QE5  P02775\n",
       "16811  Q96QE5  Q9P291\n",
       "16812  Q96QE5  Q56950\n",
       "\n",
       "[16766 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 91
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Set home directory\r\n",
    "home_dir = pathlib.Path.home().joinpath('Documents', 'ms_thesis_ppi')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "source": [
    "# check for duplicates in positive set\r\n",
    "\r\n",
    "in_file_2 = pathlib.Path.joinpath(home_dir, 'dataset','9606_Q1.txt')\r\n",
    "df_whole = pd.read_csv(in_file_2, sep=\"\\t\", header=0, dtype='unicode')\r\n",
    "df_whole = df_whole[['UniprotID_A', 'UniprotID_B']] # only keep specific columns\r\n",
    "df_whole.columns = [\"int_A\", \"int_B\"]\r\n",
    "comparison_df = neg_freq_bal_r.merge(df_whole, indicator=True, how='outer')\r\n",
    "neg_train_final_balanced = comparison_df.loc[comparison_df['_merge'] == 'left_only']\r\n",
    "neg_train_final_balanced.to_csv(\"neg_train_final_balanced.csv\", index=False)\r\n",
    "neg_train_final_balanced"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>int_A</th>\n",
       "      <th>int_B</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A1L4K1</td>\n",
       "      <td>Q81QL7</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A1L4K1</td>\n",
       "      <td>Q13563</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1L4K1</td>\n",
       "      <td>D3JIB2</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1L4K1</td>\n",
       "      <td>Q9P2Q2</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A1L4K1</td>\n",
       "      <td>P38770</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16761</th>\n",
       "      <td>Q9BVW5</td>\n",
       "      <td>Q9UEW3</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16762</th>\n",
       "      <td>Q9BVW5</td>\n",
       "      <td>Q12983</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16763</th>\n",
       "      <td>Q96QE5</td>\n",
       "      <td>P02775</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16764</th>\n",
       "      <td>Q96QE5</td>\n",
       "      <td>Q9P291</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16765</th>\n",
       "      <td>Q96QE5</td>\n",
       "      <td>Q56950</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16708 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        int_A   int_B     _merge\n",
       "0      A1L4K1  Q81QL7  left_only\n",
       "1      A1L4K1  Q13563  left_only\n",
       "2      A1L4K1  D3JIB2  left_only\n",
       "3      A1L4K1  Q9P2Q2  left_only\n",
       "4      A1L4K1  P38770  left_only\n",
       "...       ...     ...        ...\n",
       "16761  Q9BVW5  Q9UEW3  left_only\n",
       "16762  Q9BVW5  Q12983  left_only\n",
       "16763  Q96QE5  P02775  left_only\n",
       "16764  Q96QE5  Q9P291  left_only\n",
       "16765  Q96QE5  Q56950  left_only\n",
       "\n",
       "[16708 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 92
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "source": [
    "in_file_3 = pathlib.Path.joinpath(home_dir, 'dataset','neg_train_final.csv')\r\n",
    "neg_whole = pd.read_csv(in_file_3, sep=\",\", header=0, dtype='unicode')\r\n",
    "neg_frac_1 = neg_whole.sample(frac=0.45)\r\n",
    "neg_frac_2 = neg_train_final_balanced.sample(frac=0.2)\r\n",
    "neg_ref_bal = pd.concat([neg_frac_1, neg_frac_2])\r\n",
    "neg_ref_bal.to_csv('neg_ref_bal.csv', index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_reduced = neg_ref_bal[['int_A', 'int_B']].sample(n=21000).reset_index(drop=True)\r\n",
    "labels_neg = list(df_reduced.index.values)\r\n",
    "# list(map('to_'.__add__,labels))\r\n",
    "ID_neg = {}\r\n",
    "label_neg = {}\r\n",
    "max_label = 1991\r\n",
    "for i in range(len(labels_neg)):\r\n",
    "    temp_list = [df_reduced.at[i, 'int_A'], df_reduced.at[i, 'int_B']]\r\n",
    "    ID_neg[str(max_label+i)] = temp_list\r\n",
    "    label_neg[str(max_label+i)] = 0\r\n"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "source": [
    "def save_json(filename, data):\r\n",
    "    with open(filename, 'w') as fp:\r\n",
    "        json.dump(data, fp)\r\n",
    "\r\n",
    "        \r\n",
    "pos_file = pathlib.Path.joinpath(home_dir, 'dataset', 'train', 'train_positive.csv')\r\n",
    "df = pd.read_csv(pos_file, sep=\",\", dtype='unicode')\r\n",
    "labels = list(df.index.values)\r\n",
    "# list(map('to_'.__add__,labels))\r\n",
    "ID = {}\r\n",
    "label_pos = {}\r\n",
    "max_label = 0\r\n",
    "for i in range(len(labels)):\r\n",
    "    temp_list = [df.at[i, 'int_A'], df.at[i, 'int_B']]\r\n",
    "    ID[str(labels[i])] = temp_list\r\n",
    "    label_pos[str(labels[i])] = 1\r\n",
    "    max_label = i+1\r\n",
    "\r\n",
    "full_train_set = {**ID, **ID_neg}\r\n",
    "#print(sys.getsizeof(full_train_set))\r\n",
    "save_json('full_train_set_balanced.json', full_train_set)\r\n",
    "    \r\n",
    "full_train_label = {**label_pos, **label_neg}\r\n",
    "save_json('full_train_label_balanced.json', full_train_label)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pathlib \r\n",
    "import random\r\n",
    "\r\n",
    "train_full_imb = open(\"full_train_set.json\")\r\n",
    "train_dict = json.load(train_full_imb)\r\n",
    "all_keys = list(train_dict.keys())\r\n",
    "pos_keys = all_keys[:1990]\r\n",
    "neg_keys = all_keys[1990:]\r\n",
    "random.shuffle(neg_keys)\r\n",
    "#print(neg_keys)\r\n",
    "neg_key_b = neg_keys[:2000]\r\n",
    "#print(len(neg_key_b))\r\n",
    "balanced_train_set = pos_keys + neg_key_b\r\n",
    "print(len(balanced_train_set))\r\n",
    "train_bal_dict = dict()\r\n",
    "for i in balanced_train_set:\r\n",
    "    train_bal_dict[i] = train_dict[i]"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "print(len(train_bal_dict))\r\n",
    "# print(train_dict['20684'])\r\n",
    "with open('full_train_set_b.json', 'w') as fp:\r\n",
    "    json.dump(train_bal_dict, fp)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3990\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#get extra proteins\r\n",
    "old_p = pathlib.Path.joinpath(home_dir, 'dataset','train', 'full_train_set.json')\r\n",
    "new_p = pathlib.Path.joinpath(home_dir, 'dataset','train', 'full_train_set_balanced.json')\r\n",
    "d1 = open(old_p)\r\n",
    "d2 = open(new_p)\r\n",
    "full = json.load(d1)\r\n",
    "bal = json.load(d2)\r\n",
    "key_f = full.keys()\r\n",
    "key_b = bal.keys()\r\n",
    "l_f = []\r\n",
    "for k in key_f:\r\n",
    "    l_f.append(full[k][0])\r\n",
    "    l_f.append(full[k][1])\r\n",
    "l_f_filtered = list(set(l_f))\r\n",
    "l_b = []\r\n",
    "for k in key_b:\r\n",
    "    l_b.append(bal[k][0])\r\n",
    "    l_b.append(bal[k][1])\r\n",
    "l_b_filtered = list(set(l_b))\r\n",
    "extra_prot = list(set(l_b_filtered)-set(l_f_filtered))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}